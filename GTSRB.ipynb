{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **I. Acquiring dataset and exploratory data analysis**\n"
      ],
      "metadata": {
        "id": "GELWWRZWAXNj"
      },
      "id": "GELWWRZWAXNj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b78168",
      "metadata": {
        "id": "00b78168"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing dependencies\n",
        "import numpy as np\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers # False warning\n",
        "import csv\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "!pip install silence_tensorflow\n",
        "import silence_tensorflow.auto\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading dataset\n",
        "!gdown \"https://drive.google.com/uc?id=1fSu9gWbu4MOf7N9u7ir9D5Z6xbKJJnZp&confirm=t\""
      ],
      "metadata": {
        "id": "pYtg7mLtdmGS"
      },
      "id": "pYtg7mLtdmGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting dataset\n",
        "with ZipFile(\"GTSRB_dataset.zip\", 'r') as zip:\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall('/content/GTSRB_dataset')\n",
        "    zip.close()\n",
        "    print('Extraction done!')"
      ],
      "metadata": {
        "id": "ERN1g-pdiKka"
      },
      "id": "ERN1g-pdiKka",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substiting class names with real class names\n",
        "classes = { 0:'Speed limit (20km/h)',\n",
        "            1:'Speed limit (30km/h)', \n",
        "            2:'Speed limit (50km/h)', \n",
        "            3:'Speed limit (60km/h)', \n",
        "            4:'Speed limit (70km/h)', \n",
        "            5:'Speed limit (80km/h)', \n",
        "            6:'End of speed limit (80km/h)', \n",
        "            7:'Speed limit (100km/h)', \n",
        "            8:'Speed limit (120km/h)', \n",
        "            9:'No passing', \n",
        "            10:'No passing veh over 3.5 tons', \n",
        "            11:'Right-of-way at intersection', \n",
        "            12:'Priority road', \n",
        "            13:'Yield', \n",
        "            14:'Stop', \n",
        "            15:'No vehicles', \n",
        "            16:'Veh > 3.5 tons prohibited', \n",
        "            17:'No entry', \n",
        "            18:'General caution', \n",
        "            19:'Dangerous curve left', \n",
        "            20:'Dangerous curve right', \n",
        "            21:'Double curve', \n",
        "            22:'Bumpy road', \n",
        "            23:'Slippery road', \n",
        "            24:'Road narrows on the right', \n",
        "            25:'Road work', \n",
        "            26:'Traffic signals', \n",
        "            27:'Pedestrians', \n",
        "            28:'Children crossing', \n",
        "            29:'Bicycles crossing', \n",
        "            30:'Beware of ice/snow',\n",
        "            31:'Wild animals crossing', \n",
        "            32:'End speed + passing limits', \n",
        "            33:'Turn right ahead', \n",
        "            34:'Turn left ahead', \n",
        "            35:'Ahead only', \n",
        "            36:'Go straight or right', \n",
        "            37:'Go straight or left', \n",
        "            38:'Keep right', \n",
        "            39:'Keep left', \n",
        "            40:'Roundabout mandatory', \n",
        "            41:'End of no passing', \n",
        "            42:'End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "id": "gCJGptEYnCOl"
      },
      "id": "gCJGptEYnCOl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing the distribution of the different classes\n",
        "DATASET_PATH = '/content/GTSRB_dataset'\n",
        "TRAIN_SET_PATH = '/content/GTSRB_dataset/Train'\n",
        "TEST_SET_PATH = '/content/GTSRB_dataset/Test'\n",
        "folders = os.listdir(TRAIN_SET_PATH)\n",
        "\n",
        "train_number = []\n",
        "class_num = []\n",
        "\n",
        "for folder in folders:\n",
        "    train_files = os.listdir(TRAIN_SET_PATH + '/' + folder)\n",
        "    train_number.append(len(train_files))\n",
        "    class_num.append(classes[int(folder)])\n",
        "    \n",
        "# Plotting the number of images in each class\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.bar(class_num, train_number)\n",
        "plt.xticks(class_num, rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDZT1HDJHbdC"
      },
      "id": "YDZT1HDJHbdC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing sample images\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "num_of_classes = len(os.listdir(TRAIN_SET_PATH))\n",
        "sample_plt_col, sample_plt_row = 4,4\n",
        "\n",
        "for plot in range(1, sample_plt_col*sample_plt_row +1):\n",
        "    rand_class = np.random.randint(num_of_classes)\n",
        "    class_numbers = os.listdir('/content/GTSRB_dataset/Train')\n",
        "    rand_folder = os.listdir('/content/GTSRB_dataset/Train/' + class_numbers[rand_class])\n",
        "    ax = fig.add_subplot(sample_plt_col, sample_plt_row, plot)\n",
        "    img = np.array(PIL.Image.open('/content/GTSRB_dataset/Train/' + str(class_numbers[rand_class]) + '/' + np.random.choice(rand_folder)))\n",
        "    plt.imshow(img)\n",
        "    ax.set_title(str(classes[int(class_numbers[rand_class])]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iKVqqKf-0dX3"
      },
      "id": "iKVqqKf-0dX3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **II. Loading dataset and data augmentation**\n"
      ],
      "metadata": {
        "id": "hCQ2_ZmPvypZ"
      },
      "id": "hCQ2_ZmPvypZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameters for data loading\n",
        "TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, TEST_BATCH_SIZE = 32,32,32\n",
        "IMG_HEIGHT, IMG_WIDTH = 40, 40\n",
        "VAL_SPLIT_RATIO = 0.2"
      ],
      "metadata": {
        "id": "iD5KUhwSkfcN"
      },
      "id": "iD5KUhwSkfcN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading training data\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_SET_PATH,\n",
        "    validation_split = VAL_SPLIT_RATIO,\n",
        "    subset = \"training\",\n",
        "    seed=123,\n",
        "    image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size = (TRAIN_BATCH_SIZE)\n",
        ")\n",
        "\n",
        "# Loading training validation data\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_SET_PATH,\n",
        "    validation_split = VAL_SPLIT_RATIO,\n",
        "    subset = \"validation\",\n",
        "    seed=123,\n",
        "    image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size = (VAL_BATCH_SIZE)\n",
        ")\n",
        "\n",
        "# train_ds_iterator = train_ds.as_numpy_iterator()\n",
        "# batch = train_ds_iterator.next()"
      ],
      "metadata": {
        "id": "y2pnEgFYk3-x"
      },
      "id": "y2pnEgFYk3-x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomTranslation(height_factor=(-0.1, 0.1),width_factor=(-0.1, 0.1)),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(height_factor=(-0.2, 0.2),width_factor=(-0.2, 0.2)),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "    layers.RandomBrightness(factor=0.05)\n",
        "])\n",
        "\n",
        "def augmentation(ds):\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds_aug = augmentation(train_ds)\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.show()\n",
        "# Showing augmented sample data\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(tf.expand_dims(img,0))\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0]/255)"
      ],
      "metadata": {
        "id": "toNpYMjObq3x"
      },
      "id": "toNpYMjObq3x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **III. Creating the neural network model and training it**"
      ],
      "metadata": {
        "id": "I64SwyW7wD22"
      },
      "id": "I64SwyW7wD22"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model\n",
        "num_classes = len(train_ds.class_names)\n",
        "\n",
        "model = tf.keras.models.Sequential([    \n",
        "    layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,3)),\n",
        "    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(rate=0.5),\n",
        "    \n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "afaAV7KVLwfQ"
      },
      "id": "afaAV7KVLwfQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rRWCdYYeMB_5"
      },
      "id": "rRWCdYYeMB_5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "epochs=20\n",
        "history = model.fit(\n",
        "  train_ds_aug,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  shuffle=True)"
      ],
      "metadata": {
        "id": "FJpff4lzMJsw"
      },
      "id": "FJpff4lzMJsw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3B6mQEgUMbrn"
      },
      "id": "3B6mQEgUMbrn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IV. Testing and performance evaluation**"
      ],
      "metadata": {
        "id": "X8Tx83zXwoBJ"
      },
      "id": "X8Tx83zXwoBJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the test set\n",
        "def make_test_set_manual():\n",
        "  # reading the CSV file\n",
        "  test_csv = pd.read_csv('/content/GTSRB_dataset/Test.csv')\n",
        "  test_img_paths = test_csv[\"Path\"].values\n",
        "  test_labels = test_csv[\"ClassId\"].values\n",
        "  int_test_labels = [int(label) for label in test_labels]\n",
        "  test_ds = []\n",
        "\n",
        "  for img in test_img_paths:\n",
        "    image = tf.keras.utils.load_img(DATASET_PATH + '/' + img, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "    img_array = tf.keras.utils.img_to_array(image)\n",
        "    test_ds.append(np.array(img_array))\n",
        "\n",
        "  X_test = np.array(test_ds)\n",
        "\n",
        "  return X_test, test_labels, test_img_paths\n",
        "\n",
        "\n",
        "def manual_test(x,y,batch_size):\n",
        "  pred_set = model.predict(X_test,batch_size=TEST_BATCH_SIZE)\n",
        "  prediction_set = []\n",
        "  corr = 0\n",
        "  for iter in range(pred_set.shape[0]):\n",
        "    scores = tf.nn.softmax(pred_set[iter])\n",
        "    prediction = int(train_ds.class_names[np.argmax(scores)])\n",
        "    prediction_set.append(prediction)\n",
        "  for idx, pred in enumerate(prediction_set):\n",
        "    if pred == test_labels[idx]:\n",
        "      corr += 1\n",
        "  accuracy = corr/test_labels.shape[0]\n",
        "\n",
        "  return accuracy, prediction_set\n",
        "\n",
        "X_test, test_labels, test_img_paths = make_test_set_manual()\n",
        "accuracy, prediction_set = manual_test(x=X_test,y=test_labels, batch_size=TEST_BATCH_SIZE)\n",
        "print(\"\\nAccuracy: {:.5f}% on test images.\" .format(accuracy*100))"
      ],
      "metadata": {
        "id": "5-tKjPvEQ9Vp"
      },
      "id": "5-tKjPvEQ9Vp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(test_labels, prediction_set)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot()\n",
        "fig = disp.figure_\n",
        "fig.set_figwidth(12)\n",
        "fig.set_figheight(12) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6GV4u5IfwUom"
      },
      "id": "6GV4u5IfwUom",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_labels, prediction_set))"
      ],
      "metadata": {
        "id": "Gu_L9kELzpfI"
      },
      "id": "Gu_L9kELzpfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing correct prediction examples\n",
        "fig_correct = plt.figure(figsize=(20, 20))\n",
        "fig_correct.suptitle(\"Correct predictions\")\n",
        "plt_cnt = 1\n",
        "label_cnt = 0\n",
        "\n",
        "for prediction in prediction_set:\n",
        "  if prediction == test_labels[label_cnt]:\n",
        "    test_img_path = test_img_paths[label_cnt]\n",
        "    test_img = tf.keras.utils.load_img(DATASET_PATH + '/' + test_img_path)\n",
        "    img_array = tf.keras.utils.img_to_array(test_img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    ax = fig_correct.add_subplot(4, 4, plt_cnt)\n",
        "    ax.set_title(str(\"Prediction: {}\\nActual: {}\".format(classes[prediction],classes[test_labels[label_cnt]])), color = 'g')\n",
        "    plt.imshow(test_img)\n",
        "    plt_cnt += 1\n",
        "  label_cnt +=1\n",
        "  if plt_cnt == 17:\n",
        "    break\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3yzn_uTC_e-2"
      },
      "id": "3yzn_uTC_e-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing incorrect prediction examples\n",
        "fig_correct = plt.figure(figsize=(20, 20))\n",
        "fig_correct.suptitle(\"Incorrect predictions\")\n",
        "plt_cnt = 1\n",
        "label_cnt = 0\n",
        "\n",
        "for prediction in prediction_set:\n",
        "  if prediction != test_labels[label_cnt]:\n",
        "    test_img_path = test_img_paths[label_cnt]\n",
        "    test_img = tf.keras.utils.load_img(DATASET_PATH + '/' + test_img_path)\n",
        "    img_array = tf.keras.utils.img_to_array(test_img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    ax = fig_correct.add_subplot(4, 4, plt_cnt)\n",
        "    ax.set_title(str(\"Prediction: {}\\nActual: {}\".format(classes[prediction],classes[test_labels[label_cnt]])), color = 'r')\n",
        "    plt.imshow(test_img)\n",
        "    plt_cnt += 1\n",
        "  label_cnt +=1\n",
        "  if plt_cnt == 17:\n",
        "    break\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bhS5u4GETPv1"
      },
      "id": "bhS5u4GETPv1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing heatmaps of convolutional layers\n",
        "layer_outputs = [layer.output for layer in model.layers if isinstance(layer, layers.Conv2D)]\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "num_of_vis_images = 10\n",
        "\n",
        "for i in range(num_of_vis_images):\n",
        "  img = tf.keras.preprocessing.image.load_img('/content/GTSRB_dataset/Test/'+ np.random.choice(os.listdir('/content/GTSRB_dataset/Test/')), target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "  img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "  activations = activation_model.predict(img_array, verbose= 0)\n",
        "\n",
        "  fig_conv = plt.figure(figsize=(20, 20))\n",
        "  fig_conv.add_subplot(1,5,1)\n",
        "  plt.imshow(img)\n",
        "  for act in range(len(activations)):\n",
        "    fig_conv.add_subplot(1, 5, act+2)\n",
        "    plt.imshow(activations[act][0, :, :, 0], cmap='jet')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "zH_iLnzwgHJ7"
      },
      "id": "zH_iLnzwgHJ7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}